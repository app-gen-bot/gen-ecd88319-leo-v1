# Expanding access to Claude for government

**Published:** governmentJun 26, 2024
**Source:** https://www.anthropic.com/news/expanding-access-to-claude-for-government

AnnouncementsJun 26, 2024‚óè2 min  read
Anthropic's mission is to build reliable, interpretable, steerable AI systems. We have been excited to see our technology used in areas like coding, customer service, drug discovery, and medical research. We're eager to make these tools available through expanded offerings to government users. Leveraging the flexibility and security of Amazon Web Services [AWS], our AI models Claude 3 Haiku and Claude 3 Sonnet are now available in the AWS Marketplace for the US Intelligence Community [IC] and in AWS GovCloud.

Claude offers a wide range of potential applications for government agencies, both in the present and looking toward the future. Government agencies can use Claude to provide improved citizen services, streamline document review and preparation, enhance policymaking with data-driven insights, and create realistic training scenarios. In the near future, AI could assist in disaster response coordination, enhance public health initiatives, or optimize energy grids for sustainability. Used responsibly, AI has the potential to transform how elected governments serve their constituents and promote peace and security.

## Adapting to government needs

We have been carefully considering the needs of public servants about how Claude could be used to further their missions and the unique needs of government users. In addition to making our models available in the AWS marketplaces that meet stringent government security standards, we are also adapting our service agreements to the unique needs, missions, and legal authorities of governments. 

For example, we have crafted a set of [contractual exceptions](https://support.anthropic.com/en/articles/9528712-exceptions-to-our-usage-policy) to our general [Usage Policy](https://www.anthropic.com/legal/aup) that are carefully calibrated to enable beneficial uses by carefully selected government agencies. These allow Claude to be used for legally authorized foreign intelligence analysis, such as combating human trafficking, identifying covert influence or sabotage campaigns, and providing warning in advance of potential military activities, opening a window for diplomacy to prevent or deter them. All other restrictions in our general [Usage Policy](https://www.anthropic.com/legal/aup), including those concerning disinformation campaigns, the design or use of weapons, censorship, and malicious cyber operations, remain.

At present, this policy applies only to models that are at AI Safety Level 2 (ASL-2) under our[ Responsible Scaling Policy](https://www.anthropic.com/news/anthropics-responsible-scaling-policy) (RSP). As we move forward, we commit to regularly evaluating our partnerships and their impacts. Our goal remains constant: ensuring that AI serves the public interest while maintaining our empirical approach to mitigating potential risks.

## Commitment to responsible AI deployment

Since our founding, we have been committed to working to support effective government policies about AI. We have stressed the importance of working with governments to develop [effective testing and measurement regimes](https://www.anthropic.com/news/third-party-testing) and recently provided [pre-release access](https://www.anthropic.com/news/claude-3-5-sonnet) of Claude 3.5 Sonnet to the UK Artificial Intelligence Safety Institute (UK AISI), which conducted pre deployment testing and shared their results with US AI Safety Institute (US AISI). We believe working with governments is essential to ensuring the world safely makes the transition toward transformative AI and are committed to working toward this goal.

News

### Introducing the Anthropic Economic Futures Program

Jun 27, 2025

News

### How People Use Claude for Support, Advice, and Companionship

Jun 27, 2025

News

### Build and share AI-powered apps with Claude

Jun 25, 2025