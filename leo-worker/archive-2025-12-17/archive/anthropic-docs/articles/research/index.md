# Research Articles

*Total: 68 articles*

## Undated

- [Privileged Bases in the Transformer Residual Stream](privileged-bases-in-the-transformer-residual-stream.md)
- [Circuits Updates – August 2024](circuits-updates-august-2024.md)
- [Using dictionary learning features as classifiers](using-dictionary-learning-features-as-classifiers.md)
- [Tracing the thoughts of a large language model](tracing-the-thoughts-of-a-large-language-model.md)
- [A statistical approach to model evaluations](a-statistical-approach-to-model-evaluations.md)
- [Collective Constitutional AI: Aligning a Language Model with Public Input](collective-constitutional-ai-aligning-a-language-model-with-public-input.md)
- [Interpretability Dreams](interpretability-dreams.md)
- [Toy Models of Superposition](toy-models-of-superposition.md)
- [Question Decomposition Improves the Faithfulness of Model-Generated Reasoning](question-decomposition-improves-the-faithfulness-of-model-generated-reasoning.md)
- [Softmax Linear Units](softmax-linear-units.md)
- [Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned](red-teaming-language-models-to-reduce-harms-methods-scaling-behaviors-and-lessons-learned.md)
- [Discovering Language Model Behaviors with Model-Written Evaluations](discovering-language-model-behaviors-with-model-written-evaluations.md)
- [Predictability and Surprise in Large Generative Models](predictability-and-surprise-in-large-generative-models.md)
- [Circuits Updates – April 2024](circuits-updates-april-2024.md)
- [Clio: A system for privacy-preserving insights into real-world AI use](clio-a-system-for-privacy-preserving-insights-into-real-world-ai-use.md)
- [The Capacity for Moral Self-Correction in Large Language Models](the-capacity-for-moral-self-correction-in-large-language-models.md)
- [Decomposing Language Models Into Understandable Components](decomposing-language-models-into-understandable-components.md)
- [Reflections on Qualitative Research](reflections-on-qualitative-research.md)
- [Circuits Updates — May 2023](circuits-updates-may-2023.md)
- [Insights on Crosscoder Model Diffing](insights-on-crosscoder-model-diffing.md)
- [Open-sourcing circuit tracing tools](open-sourcing-circuit-tracing-tools.md)
- [Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training](sleeper-agents-training-deceptive-llms-that-persist-through-safety-training.md)
- [Evaluating and Mitigating Discrimination in Language Model Decisions](evaluating-and-mitigating-discrimination-in-language-model-decisions.md)
- [Circuits Updates – July 2024](circuits-updates-july-2024.md)
- [Reasoning models don't always say what they think](reasoning-models-dont-always-say-what-they-think.md)
- [SHADE-Arena: Evaluating sabotage and monitoring in LLM agents](shade-arena-evaluating-sabotage-and-monitoring-in-llm-agents.md)
- [Towards Measuring the Representation of Subjective Global Opinions in Language Models](towards-measuring-the-representation-of-subjective-global-opinions-in-language-models.md)
- [Tracing Model Outputs to the Training Data](tracing-model-outputs-to-the-training-data.md)
- [Forecasting rare language model behaviors](forecasting-rare-language-model-behaviors.md)
- [Scaling Laws and Interpretability of Learning from Repeated Data](scaling-laws-and-interpretability-of-learning-from-repeated-data.md)
- [Values in the wild: Discovering and analyzing values in real-world language model interactions](values-in-the-wild-discovering-and-analyzing-values-in-real-world-language-model-interactions.md)
- [Simple probes can catch sleeper agents](simple-probes-can-catch-sleeper-agents.md)
- [Anthropic Economic Index: AI’s Impact on Software Development](anthropic-economic-index-ais-impact-on-software-development.md)
- [Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback](training-a-helpful-and-harmless-assistant-with-reinforcement-learning-from-human-feedback.md)
- [Constitutional Classifiers: Defending against universal jailbreaks](constitutional-classifiers-defending-against-universal-jailbreaks.md)
- [Distributed Representations: Composition & Superposition](distributed-representations-composition-superposition.md)
- [Circuits Updates – September 2024](circuits-updates-september-2024.md)
- [Exploring model welfare](exploring-model-welfare.md)
- [Agentic Misalignment: How LLMs could be insider threats](agentic-misalignment-how-llms-could-be-insider-threats.md)
- [Many-shot jailbreaking](many-shot-jailbreaking.md)
- [Language Models (Mostly) Know What They Know](language-models-mostly-know-what-they-know.md)
- [Confidential Inference via Trusted Virtual Machines](confidential-inference-via-trusted-virtual-machines.md)
- [Sabotage evaluations for frontier models](sabotage-evaluations-for-frontier-models.md)
- [Circuits Updates – June 2024](circuits-updates-june-2024.md)
- [A Mathematical Framework for Transformer Circuits](a-mathematical-framework-for-transformer-circuits.md)
- [Measuring Progress on Scalable Oversight for Large Language Models](measuring-progress-on-scalable-oversight-for-large-language-models.md)
- [Measuring Faithfulness in Chain-of-Thought Reasoning](measuring-faithfulness-in-chain-of-thought-reasoning.md)
- [Evaluating feature steering: A case study in mitigating social biases](evaluating-feature-steering-a-case-study-in-mitigating-social-biases.md)
- [Claude’s Character](claudes-character.md)
- [The engineering challenges of scaling interpretability](the-engineering-challenges-of-scaling-interpretability.md)
- [Challenges in evaluating AI systems](challenges-in-evaluating-ai-systems.md)
- [Auditing language models for hidden objectives](auditing-language-models-for-hidden-objectives.md)
- [A General Language Assistant as a Laboratory for Alignment](a-general-language-assistant-as-a-laboratory-for-alignment.md)
- [Studying Large Language Model Generalization with Influence Functions](studying-large-language-model-generalization-with-influence-functions.md)
- [Superposition, Memorization, and Double Descent](superposition-memorization-and-double-descent.md)
- [In-context Learning and Induction Heads](in-context-learning-and-induction-heads.md)
- [Towards Understanding Sycophancy in Language Models](towards-understanding-sycophancy-in-language-models.md)
- [Mapping the Mind of a Large Language Model](mapping-the-mind-of-a-large-language-model.md)
- [Claude’s extended thinking](claudes-extended-thinking.md)
- [Constitutional AI: Harmlessness from AI Feedback](constitutional-ai-harmlessness-from-ai-feedback.md)
- [Towards Monosemanticity: Decomposing Language Models With Dictionary Learning](towards-monosemanticity-decomposing-language-models-with-dictionary-learning.md)
- [Specific versus General Principles for Constitutional AI](specific-versus-general-principles-for-constitutional-ai.md)
- [Measuring the Persuasiveness of Language Models](measuring-the-persuasiveness-of-language-models.md)
- [Alignment faking in large language models](alignment-faking-in-large-language-models.md)

## 2025

- [2025-06-27] [Project Vend: Can Claude run a small shop? (And why does that matter?)](2025-06-27-project-vend-can-claude-run-a-small-shop-and-why-does-that-matter.md)
- [2025-01-06] [Raising the bar on SWE-bench Verified with Claude 3.5 Sonnet](2025-01-06-raising-the-bar-on-swe-bench-verified-with-claude-35-sonnet.md)

## 2024

- [2024-12-19] [Building effective agents](2024-12-19-building-effective-agents.md)
- [2024-06-17] [Sycophancy to subterfuge: Investigating reward tampering in language models](2024-06-17-sycophancy-to-subterfuge-investigating-reward-tampering-in-language-models.md)
